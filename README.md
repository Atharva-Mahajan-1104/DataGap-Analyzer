

# ğŸ©º DataGap Analyzer

*A practical diagnostic and treatment toolkit for handling missing values in tabular machine-learning datasets.*

---

## ğŸš‘ Why DataGap Analyzer?

Missing values are one of the most commonâ€”and dangerousâ€”problems in real-world datasets. Ignoring them or blindly imputing can quietly degrade model performance or introduce bias.

**Missing Data Doctor** is built to answer four critical questions:

1. **How bad is the missing data problem?**
2. **Where exactly is data missingâ€”and in what patterns?**
3. **Which imputation strategy works best for this dataset?**
4. **How does each choice affect downstream ML performance?**

Instead of guessing, this tool **measures, visualizes, compares, and reports** everything in a clean, reproducible way.

---

## âœ¨ What This Tool Does

Missing Data Doctor provides an end-to-end pipeline that:

* Quantifies missing values (counts & percentages)
* Visualizes missingness across rows and columns
* Applies multiple imputation strategies
* Trains downstream ML models on each imputed dataset
* Compares performance metrics side-by-side
* Generates a **self-contained HTML report** you can share or archive

Itâ€™s designed to be:

* ğŸ”§ Drop-in for real ML workflows
* ğŸ“Š Interpretable for analysis & learning
* ğŸ§ª Portfolio-ready for GitHub

---


## âš¡ Quick Start

### 1ï¸âƒ£ Set up a virtual environment (Windows)

```bash
cd C:\Users\YourName\missing-data-doctor
python -m venv .venv
.\.venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install pandas numpy scikit-learn matplotlib seaborn jinja2
```

---

### 3ï¸âƒ£ Run the demo pipeline

```bash
python src\cli.py ^
  --data data\example_with_missing.csv ^
  --target target ^
  --task classification ^
  --out_dir outputs\runs\demo
```

This single command will:

* Load the dataset
* Profile missing values
* Generate visualizations
* Apply **3 imputation strategies**
* Train & evaluate ML models
* Write all results to a single run folder

---

### 4ï¸âƒ£ Open the report

```bash
start "" outputs\runs\demo\missing_data_doctor.html
```

No server requiredâ€”just open the file.

---

## ğŸ“ What Gets Generated

After execution, your run directory will look like:

```
outputs/runs/demo/
â”œâ”€â”€ missing_summary.csv
â”œâ”€â”€ summary.json
â”œâ”€â”€ impact.json
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ missing_bar.png
â”‚   â””â”€â”€ missing_heatmap.png
â””â”€â”€ missing_data_doctor.html
```

Each run is **self-contained** and portable.

---

## ğŸ§ª Example Dataset Explained

The demo dataset is intentionally small so patterns are easy to see:

| age | income | visits | score | target |
| --: | -----: | -----: | ----: | -----: |
|  25 |  30000 |      5 |   620 |      0 |
|  40 |        |     10 |   680 |      1 |
|  35 |  45000 |        |   640 |      0 |
|     |  70000 |     12 |   720 |      1 |
|  28 |  34000 |      6 |       |      0 |
|   â€¦ |      â€¦ |      â€¦ |     â€¦ |      â€¦ |

**Key characteristics**

* 10 rows Ã— 5 columns
* Multiple features with partial missingness
* Binary classification target
* No missing labels (ideal supervised setup)

---

## ğŸ“Š Understanding the Visualizations

### Missingness per Feature (Bar Chart)

This plot answers:

> *â€œWhich columns are hurting the most?â€*

* Tall bars â†’ higher risk features
* Low bars â†’ simpler imputation may suffice
* Zero bars â†’ safe features

This is your **first triage step**.

---

### Missingness Matrix (Heatmap)

This view answers:

> *â€œIs missingness random or structured?â€*

It helps distinguish between:

* **MCAR** â€“ scattered, random gaps
* **MAR** â€“ missingness related to other features
* **MNAR** â€“ missingness tied to the missing value itself

Understanding this directly informs which imputation strategy is safe.

---

## ğŸ§  Imputation + Model Impact

Missing Data Doctor doesnâ€™t stop at filling values.

It evaluates how imputation choices affect **real ML performance**.

### Strategies evaluated:

* **Simple** (mean / median / mode)
* **KNN Imputation**
* **Iterative Imputation (MICE-style)**

Each strategy:

* Produces a complete dataset
* Trains a Random Forest model
* Reports metrics (AUC, Accuracy, etc.)

Example (`impact.json` schema):

```json
{
  "simple": { "AUC": 0.85, "Accuracy": 0.80 },
  "knn": { "AUC": 0.87, "Accuracy": 0.82 },
  "iterative": { "AUC": 0.86, "Accuracy": 0.81 }
}
```

ğŸ“Œ **Insight:**
The â€œbestâ€ imputer is dataset-dependentâ€”and this tool proves it quantitatively.

---

## ğŸ§¾ The HTML Report

Each run generates a **standalone HTML report** that includes:

* Missing-value tables
* Embedded plots
* Model comparison metrics
* Clear sectioned layout

Because plots live alongside the report:

```
plots/missing_bar.png
plots/missing_heatmap.png
```

â€¦the report works anywhere:

* Zip it
* Email it
* Archive it
* Share it

---




---

## ğŸ” Design Philosophy

**DataGap Analyzer** is intentionally built to be:

* **Explicit** â€“ missing data is treated as a measurable risk, not a silent preprocessing step
* **Comparative** â€“ multiple imputations are evaluated side-by-side
* **Reproducible** â€“ every run produces a self-contained artifact
* **Practical** â€“ usable on real datasets, not just toy examples

The goal is not just to *fill gaps*, but to **understand their impact**.

---

## ğŸš€ Ideas for Extension

You can extend DataGap Analyzer in several directions:

* **Additional imputation strategies**

  * Mean vs median comparison
  * Domain-aware defaults (e.g., 0 for count features)
* **Missingness analysis**

  * Correlation between `is_missing(feature)` and other variables
  * Predicting missingness using logistic models
* **Fairness checks**

  * Does missing data disproportionately affect certain subgroups?
* **Time-series support**

  * Gap length analysis
  * Location of missing segments over time
* **MLOps integration**

  * Dataset monitoring
  * Regression tests for data quality drift

---

## ğŸ“Œ When to Use DataGap Analyzer

* During **EDA** to understand dataset health
* Before **model training** to choose safe imputation strategies
* In **academic projects** to justify preprocessing decisions
* In **production workflows** to compare data repair choices
* As a **portfolio project** demonstrating applied ML thinking


---

## â­ Final Note

Missing data is rarely randomâ€”and rarely harmless.
**DataGap Analyzer** helps you treat it as a first-class problem, not an afterthought.

---

